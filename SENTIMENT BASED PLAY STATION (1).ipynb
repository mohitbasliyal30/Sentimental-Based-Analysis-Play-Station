{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENTIMENT BASED PLAYSTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from nltk.corpus import stopwords\n",
    "import speech_recognition as sr\n",
    "from deepface import DeepFace\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "from gtts import gTTS\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import statistics\n",
    "import playsound\n",
    "import keyword\n",
    "import pyaudio\n",
    "import pyglet\n",
    "import nltk\n",
    "import cv2\n",
    "import time\n",
    "import os \n",
    "import re\n",
    "import warnings\n",
    "import ctypes\n",
    "import time\n",
    "from imutils.video import VideoStream\n",
    "import argparse\n",
    "import imutils\n",
    "import pyttsx3\n",
    "#nltk.download('stopwords')\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "#nltk.download('punkt')\n",
    "emotion_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control():\n",
    "    \n",
    "    \n",
    "    #direct keys\n",
    "    SendInput = ctypes.windll.user32.SendInput\n",
    "\n",
    "\n",
    "    W = 0x11\n",
    "    A = 0x1E\n",
    "    S = 0x1F\n",
    "    D = 0x20\n",
    "\n",
    "    # C struct redefinitions \n",
    "    PUL = ctypes.POINTER(ctypes.c_ulong)\n",
    "    class KeyBdInput(ctypes.Structure):\n",
    "        _fields_ = [(\"wVk\", ctypes.c_ushort),\n",
    "                    (\"wScan\", ctypes.c_ushort),\n",
    "                    (\"dwFlags\", ctypes.c_ulong),\n",
    "                    (\"time\", ctypes.c_ulong),\n",
    "                    (\"dwExtraInfo\", PUL)]\n",
    "\n",
    "    class HardwareInput(ctypes.Structure):\n",
    "        _fields_ = [(\"uMsg\", ctypes.c_ulong),\n",
    "                    (\"wParamL\", ctypes.c_short),\n",
    "                    (\"wParamH\", ctypes.c_ushort)]\n",
    "\n",
    "    class MouseInput(ctypes.Structure):\n",
    "        _fields_ = [(\"dx\", ctypes.c_long),\n",
    "                    (\"dy\", ctypes.c_long),\n",
    "                    (\"mouseData\", ctypes.c_ulong),\n",
    "                    (\"dwFlags\", ctypes.c_ulong),\n",
    "                    (\"time\",ctypes.c_ulong),\n",
    "                    (\"dwExtraInfo\", PUL)]\n",
    "\n",
    "    class Input_I(ctypes.Union):\n",
    "        _fields_ = [(\"ki\", KeyBdInput),\n",
    "                     (\"mi\", MouseInput),\n",
    "                     (\"hi\", HardwareInput)]\n",
    "\n",
    "    class Input(ctypes.Structure):\n",
    "        _fields_ = [(\"type\", ctypes.c_ulong),\n",
    "                    (\"ii\", Input_I)]\n",
    "\n",
    "    # Actuals Functions\n",
    "\n",
    "    def PressKey(hexKeyCode):\n",
    "        extra = ctypes.c_ulong(0)\n",
    "        ii_ = Input_I()\n",
    "        ii_.ki = KeyBdInput( 0, hexKeyCode, 0x0008, 0, ctypes.pointer(extra) )\n",
    "        x = Input( ctypes.c_ulong(1), ii_ )\n",
    "        ctypes.windll.user32.SendInput(1, ctypes.pointer(x), ctypes.sizeof(x))\n",
    "\n",
    "    def ReleaseKey(hexKeyCode):\n",
    "        extra = ctypes.c_ulong(0)\n",
    "        ii_ = Input_I()\n",
    "        ii_.ki = KeyBdInput( 0, hexKeyCode, 0x0008 | 0x0002, 0, ctypes.pointer(extra) )\n",
    "        x = Input( ctypes.c_ulong(1), ii_ )\n",
    "        ctypes.windll.user32.SendInput(1, ctypes.pointer(x), ctypes.sizeof(x))\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        PressKey(0x11)\n",
    "        time.sleep(1)\n",
    "        ReleaseKey(0x11)\n",
    "        time.sleep(1)\n",
    "    \n",
    "\n",
    "    # define the lower and upper boundaries of the \"orange\" object in the HSV color space\n",
    "    orangeLower = np.array([0, 129, 100])\n",
    "    orangeUpper = np.array([180,255,255])\n",
    "\n",
    "    vs = VideoStream(src=0).start()\n",
    "\n",
    "    # allow the camera or video file to warm up\n",
    "    time.sleep(2.0)\n",
    "    initial = True\n",
    "    flag = False\n",
    "    current_key_pressed = set()\n",
    "    circle_radius = 30\n",
    "    windowSize = 160\n",
    "    lr_counter = 0\n",
    "    # keep looping\n",
    "    while True:\n",
    "        keyPressed = False\n",
    "        keyPressed_lr = False\n",
    "        # grab the current frame\n",
    "        frame = vs.read()\n",
    "        height,width = frame.shape[:2]\n",
    "\n",
    "        # resize the frame, blur it, and convert it to the HSV color space\n",
    "        frame = imutils.resize(frame, width=600)\n",
    "        blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "        hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # crteate a mask for the orange color and perform dilation and erosion to remove any small\n",
    "        # blobs left in the mask\n",
    "        mask = cv2.inRange(hsv, orangeLower, orangeUpper)\n",
    "        mask = cv2.erode(mask, None, iterations=2)\n",
    "        mask = cv2.dilate(mask, None, iterations=2)\n",
    "\n",
    "        # find contours in the mask and initialize the current\n",
    "        # (x, y) center of the orange object\n",
    "\n",
    "        # divide the frame into two halves so that we can have one half control the acceleration/brake \n",
    "        # and other half control the left/right steering.\n",
    "        left_mask = mask[:,0:width//2,]\n",
    "        right_mask = mask[:,width//2:,]\n",
    "\n",
    "        #find the contours in the left and right frame to find the center of the object\n",
    "        cnts_left = cv2.findContours(left_mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts_left = imutils.grab_contours(cnts_left)\n",
    "        center_left = None\n",
    "\n",
    "        cnts_right = cv2.findContours(right_mask.copy(), cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cnts_right = imutils.grab_contours(cnts_right)\n",
    "        center_right = None\n",
    "\n",
    "        # only proceed if at least one contour was found\n",
    "        if len(cnts_left) > 0:\n",
    "            # find the largest contour in the mask, then use\n",
    "            # it to compute the minimum enclosing circle and centroid\n",
    "            c = max(cnts_left, key=cv2.contourArea)\n",
    "            ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "            M = cv2.moments(c)\n",
    "            # find the center from the moments 0.000001 is added to the denominator so that divide by \n",
    "            # zero exception doesn't occur\n",
    "            center_left = (int(M[\"m10\"] / (M[\"m00\"]+0.000001)), int(M[\"m01\"] / (M[\"m00\"]+0.000001)))\n",
    "\n",
    "            # only proceed if the radius meets a minimum size\n",
    "            if radius > circle_radius:\n",
    "                # draw the circle and centroid on the frame,\n",
    "                cv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "                    (0, 255, 255), 2)\n",
    "                cv2.circle(frame, center_left, 5, (0, 0, 255), -1)\n",
    "\n",
    "                #the window size is kept 160 pixels in the center of the frame(80 pixels above the center and 80 below)\n",
    "                if center_left[1] < (height/2 - windowSize//2):\n",
    "                    cv2.putText(frame,'LEFT',(20,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255))\n",
    "                    PressKey(A)\n",
    "                    current_key_pressed.add(A)\n",
    "                    keyPressed = True\n",
    "                    keyPressed_lr = True\n",
    "                elif center_left[1] > (height/2 + windowSize//2):\n",
    "                    cv2.putText(frame,'RIGHT',(20,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255))\n",
    "                    PressKey(D)\n",
    "                    current_key_pressed.add(D)\n",
    "                    keyPressed = True\n",
    "                    keyPressed_lr = True\n",
    "\n",
    "        # only proceed if at least one contour was found\n",
    "        if len(cnts_right) > 0:\n",
    "            c2 = max(cnts_right, key=cv2.contourArea)\n",
    "            ((x2, y2), radius2) = cv2.minEnclosingCircle(c2)\n",
    "            M2 = cv2.moments(c2)\n",
    "            center_right = (int(M2[\"m10\"] / (M2[\"m00\"]+0.000001)), int(M2[\"m01\"] / (M2[\"m00\"]+0.000001)))\n",
    "            center_right = (center_right[0]+width//2,center_right[1])\n",
    "\n",
    "            # only proceed if the radius meets a minimum size\n",
    "            if radius2 > circle_radius:\n",
    "                # draw the circle and centroid on the frame,\n",
    "                cv2.circle(frame, (int(x2)+width//2, int(y2)), int(radius2),\n",
    "                    (0, 255, 255), 2)\n",
    "                cv2.circle(frame, center_right, 5, (0, 0, 255), -1)\n",
    "                if center_right[1] < (height//2 - windowSize//2):\n",
    "                    cv2.putText(frame,'UP',(200,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255))\n",
    "                    PressKey(W)\n",
    "                    keyPressed = True\n",
    "                    current_key_pressed.add(W)\n",
    "                elif center_right[1] > (height//2 + windowSize//2):\n",
    "                    cv2.putText(frame,'DOWN',(200,50),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255))\n",
    "                    PressKey(S)\n",
    "                    keyPressed = True\n",
    "                    current_key_pressed.add(S)\n",
    "\n",
    "\n",
    "        # show the frame to our screen\n",
    "        frame_copy = frame.copy()\n",
    "        frame_copy = cv2.rectangle(frame_copy,(0,height//2 - windowSize//2),(width,height//2 + windowSize//2),(255,0,0),2)\n",
    "        cv2.imshow(\"Frame\", frame_copy)\n",
    "\n",
    "        #We need to release the pressed key if none of the key is pressed else the program will keep on sending\n",
    "        # the presskey command \n",
    "        if not keyPressed and len(current_key_pressed) != 0:\n",
    "            for key in current_key_pressed:\n",
    "                ReleaseKey(key)\n",
    "            current_key_pressed = set()\n",
    "\n",
    "        #to release keys for left/right with keys of up/down remain pressed   \n",
    "        if not keyPressed_lr and ((A in current_key_pressed) or (D in current_key_pressed)):\n",
    "            if A in current_key_pressed:\n",
    "                ReleaseKey(A)\n",
    "                current_key_pressed.remove(A)\n",
    "            elif D in current_key_pressed:\n",
    "                ReleaseKey(D)\n",
    "                current_key_pressed.remove(D)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the 'q' key is pressed, stop the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "\n",
    "    vs.stop() \n",
    "    # close all windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMOTION RECOGNITION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout = 45   # [seconds]\n",
    "def emotion():\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "    timeout_start = time.time()\n",
    "    cap=cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "            ret,frame=cap.read()\n",
    "            result=DeepFace.analyze(frame,actions= ['emotion'] )\n",
    "            gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(gray, 1.1,4)\n",
    "\n",
    "\n",
    "            for(x,y,w,h) in faces:\n",
    "                cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "            font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "            emotion_list.append(result['dominant_emotion'])\n",
    "            cv2.putText(frame,result['dominant_emotion'],(50,50), font,3,(0,0,255),2,cv2.LINE_4)\n",
    "            cv2.imshow('Original video',frame)\n",
    "            print(result['dominant_emotion'])\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "            if k == 27: # press 'ESC' to quit\n",
    "                break\n",
    "            elif time.time() >= timeout_start + timeout:\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    mode_emotion=statistics.mode(emotion_list)\n",
    "    return mode_emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT TO SPEECH FUNCTION\n",
    "\n",
    "#### gTTS:\n",
    "gTTs or google text to speech is a python library and CLI tool to interface with google translate text to speech API\n",
    "\n",
    "#### Features:\n",
    " • Customizable speech-specific sentence tokenizer that allows for unlimited lengths of text to be read, all while keeping proper intonation, abbreviations, decimals and more\n",
    " \n",
    "•Customizable text pre-processors which can, for example, provide pronunciation corrections;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_speak(spk):\n",
    "    tts = gTTS(text=spk, lang='en' , slow=False )\n",
    "    filename = 'voice.mp3'\n",
    "    tts.save(filename)\n",
    "    function_assistant_speak(1)\n",
    "    music=pyglet.media.load(filename)\n",
    "    music.play()\n",
    "    #prevent from killing\n",
    "    time.sleep(music.duration)\n",
    "    #remove temperory file\n",
    "    os.remove(filename) \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_assistant_speak(val):\n",
    "    if val == 1:\n",
    "        filename='Start_listening.mp3'\n",
    "    elif val == 2:\n",
    "        filename = 'Start_processing.mp3'\n",
    "    else:\n",
    "        filename ='Start_speaking.mp3'\n",
    "    \n",
    "    music = pyglet.media.load(filename, streaming=False)\n",
    "    music.play()\n",
    "    time.sleep(music.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPEECH TO TEXT FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speech to text function \n",
    "def get_audio(stop):\n",
    "    while True:\n",
    "        #creating object\n",
    "        r=sr.Recognizer()\n",
    "        #taking access from microphone\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"TALK\")\n",
    "            function_assistant_speak(1)\n",
    "            audio=r.listen(source)\n",
    "            function_assistant_speak(2)\n",
    "            print(\"Time over, thanks\")\n",
    "            \n",
    "        try:\n",
    "            said=r.recognize_google(audio)\n",
    "            print(\"Text : \"+said)\n",
    "            #tokenising the text\n",
    "            x=nltk.word_tokenize(said) \n",
    "            stopword = set(stop)\n",
    "            #removing stopwords\n",
    "            filtered_sentence = [w for w in x if not w in stopword]\n",
    "            return filtered_sentence\n",
    "            break\n",
    "        except:\n",
    "            function_assistant_speak(3)\n",
    "            function_speak(\"Sorry, I did not get that. Kindly repeat.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created another function for stt with specified stop words\n",
    "def get_audio2(check):\n",
    "    if(check==True):\n",
    "        stop = stopwords.words(\"english\")\n",
    "    else:\n",
    "        stop=[]\n",
    "    return get_audio(stop)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert list to string\n",
    "def listToString(s): \n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    # traverse in the string  \n",
    "    for ele in s: \n",
    "        str1 += ele \n",
    "    return str1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION TO CALL AAPS FROM SYSTEM\n",
    "#### SUBPROCESS:\n",
    "The subprocess module present in Python(both 2.x and 3.x) is used to run new applications or programs through Python code by creating new processes. It also helps to obtain the input/output/error pipes as well as the exit codes of various commands.\n",
    "\n",
    "To execute different programs using Python two functions of the subprocess module are used:\n",
    "##### 1.subprocess.check_call(args, *, stdin=None, stdout=None, stderr=None, shell=False)\n",
    "##### 2.subprocess.check_output(args, *, stdin=None, stderr=None, shell=False, universal_newlines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apps():\n",
    "    while (True):\n",
    "        stop=stopwords.words(\"english\") + [\"hi\",\"name\",\"open\",\"'s\"]\n",
    "        x=get_audio(stop)\n",
    "        \n",
    "        if('calculator' in x):\n",
    "            function_speak(\"Opening calculator!\")\n",
    "            subprocess.call(\"C:\\Windows\\System32\\calc.exe\")\n",
    "            function_speak(\"Calculator opened\")\n",
    "            break;\n",
    "        else:\n",
    "            function_speak(\"Sorry, I did not get that. Kindly repeat.\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns current time\n",
    "def get_time():\n",
    "    now = datetime.now()\n",
    "    #getting time in specific time fromat\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    function_speak(current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION TO CALL GAMES FROM SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def games():\n",
    "    while (True):\n",
    "        stop=stopwords.words(\"english\") + [\"hi\",\"name\",\"open\",\"'s\",\"I\",\"want\",\"play\",\"need\"]\n",
    "        g=get_audio(stop)\n",
    "        if ('speed' in g) or ('Speed' in g):\n",
    "            #opening folder\n",
    "            \n",
    "            os.startfile(r'C:\\\\Program Files (x86)\\\\R.G. Mechanics\\\\Need for Speed Most Wanted')\n",
    "            function_speak(\"Taking you to a! new gaming world\")\n",
    "            control()\n",
    "            break;\n",
    "        else:\n",
    "            function_speak(\"Sorry, I did not get that. Kindly repeat.\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION TO FETCH URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url(text): \n",
    "    fin=re.findall('(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+',text)\n",
    "    for i in fin:\n",
    "        if \".\" in i:\n",
    "            return i        \n",
    "    print(fin)\n",
    "    if \".\" in fin:\n",
    "        return fin[fin.index(\".\")-1]+\".\"+fin[fin.index(\".\")+1]\n",
    "        #break\n",
    "    elif \"dot\" in fin:\n",
    "        return fin[fin.index(\"dot\")-1]+\".\"+fin[fin.index(\"dot\")+1]\n",
    "        #break\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PINGING THE WEBSITES USING SELENIUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch(z):\n",
    "    #setting up the chrome driver\n",
    "    driver=webdriver.Chrome(executable_path=\"chromedriver.exe\")\n",
    "    driver.get(\"http://\"+z.strip()+\"/\")\n",
    "\n",
    "def ping():\n",
    "    l=get_audio2(False)\n",
    "    print(l)\n",
    "    s = \" \"\n",
    "    # joins elements of list1 by ' ' \n",
    "    # and stores in sting s \n",
    "    s = s.join(l)\n",
    "    y = s.lower()\n",
    "    z = url(y)\n",
    "    function_speak(\"Is this website correct \"+z+\". yes or no?\")\n",
    "    a=\"\"\n",
    "    l=get_audio2(False)\n",
    "    a=a.join(l)\n",
    "    a=a.lower()\n",
    "    a=a.strip()\n",
    "    if (a == \"yes\"):\n",
    "        function_speak(\"establishing a connection!\")\n",
    "        fetch(z)\n",
    "    else:\n",
    "        function_speak(\"Speak again\")\n",
    "        ping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION TO LAUNCH OUR PLAYSTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={}\n",
    "def main_function():\n",
    "        if(len(dict1.keys())!=0):\n",
    "            function_assistant_speak(3)\n",
    "            function_speak(\"Hi \"+s+\". What do you want to do ?\")\n",
    "            get_audio2(False)\n",
    "        else:\n",
    "            stop=stopwords.words(\"english\") + [\"hi\",\"name\",\"open\",\"'s\",\"assistant\"]\n",
    "            function_speak(\"Good afternoon! Rajiv sir! and Digvijay sir\")\n",
    "            function_speak(\"NAMASHKAR! AAPKA SWAGAT HAI hamari DILCHASP DUNIYA ME\")\n",
    "            function_speak(\"Welcome to Playstation! Analyzing your emotion \")\n",
    "            #returning the sentiment analyzed by emotion function \n",
    "            sentiment=emotion()\n",
    "            function_speak(\"May I know your good name\")\n",
    "            l = get_audio(stop)\n",
    "            if(len(l)==0):\n",
    "                l=get_audio(stop)\n",
    "            s = \" \"\n",
    "            s = s.join(l) \n",
    "            dict1['name']=s\n",
    "            #creating loop to call our features as many times as possible\n",
    "            while(True):\n",
    "                function_speak(\"Hi \"+s+\". What can i do for you ?\")\n",
    "                a= get_audio(stop)\n",
    "                if(len(a)==0):\n",
    "                    a=get_audio(stop)\n",
    "                    \n",
    "                if('app' in a)or('apps' in a)or('Apps' in a)or('App' in a)or('aap' in a)or('Aap' in a):\n",
    "                    function_speak(\"Which app do you want to open!\")\n",
    "                    apps()\n",
    "                    \n",
    "                elif('game'in a)or('Game'in a)or('Games'in a)or('games'in a):\n",
    "                    function_speak(\"You seem to be\"+sentiment+\"You should play need for speed but Which game do you want to play!\")\n",
    "                    games()\n",
    "                    \n",
    "                elif('website'in a)or('websites'in a)or('Website'in a)or('Websites'in a):\n",
    "                    function_speak(\"please name the website you want to visit!\")\n",
    "                    ping()\n",
    "                    \n",
    "                elif('time'in a)or('times'in a)or('Time'in a)or('Times'in a):\n",
    "                    get_time()\n",
    "                    \n",
    "                elif('close'in a)or('Close'in a):\n",
    "                    function_speak(\"NOW! closing the assistant!\")\n",
    "                    function_speak(\"Thank you to Dhruv. AAshish. yash. mohit. and jahnvi. for making me. \")\n",
    "                    function_speak(\"Thank you Digvijay Sir for guiding them! Goodbye\") \n",
    "                    \n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    function_speak(\"Sorry, I did not get that. Kindly repeat.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002629F969DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "neutral\n",
      "neutral\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "neutral\n",
      "happy\n",
      "happy\n",
      "happy\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : my name is Yash\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : I want you to open an app for me\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : calculator\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : I want you to open an website\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : youtube.com\n",
      "['youtube.com']\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : yes\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : ab Mera game khelne ka man ho raha hai to Tum game laga do koi\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : theek hai Need for Speed khelta hai\n",
      "TALK\n",
      "Time over, thanks\n",
      "Text : ok I want you to close the assistant now\n"
     ]
    }
   ],
   "source": [
    "main_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
